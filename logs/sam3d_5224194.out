[DEBUG] train_dataset length = 120
Loaded checkpoint from /dss/dsshome1/0D/ru47tac2/projects/segrap2025/results/segrap_ft_resume/sam_model_latest.pth (epoch 128)
Epoch: 128/199
Epoch: 128, Step: 20, Loss: -2.543739968538284, Dice: 0.15222680568695068
Epoch: 128, Step: 40, Loss: -2.266245874762535, Dice: 0.10879939794540405
EPOCH: 128, Loss: -2.5818800419569015
EPOCH: 128, Dice: 0.16619096733629704
Epoch: 129/199
Epoch: 129, Step: 20, Loss: -2.4906402587890626, Dice: 0.11130796372890472
Epoch: 129, Step: 40, Loss: -2.489139273762703, Dice: 0.29847487807273865
EPOCH: 129, Loss: -2.5148682703574496
EPOCH: 129, Dice: 0.1609822276979685
Epoch: 130/199
Epoch: 130, Step: 20, Loss: -2.525919759273529, Dice: 0.18334323167800903
Epoch: 130, Step: 40, Loss: -2.2506129264831545, Dice: 0.2356666624546051
EPOCH: 130, Loss: -2.4454438984394073
EPOCH: 130, Dice: 0.15786565989255905
Epoch: 131/199
Epoch: 131, Step: 20, Loss: -2.696253776550293, Dice: 0.09490036964416504
Epoch: 131, Step: 40, Loss: -2.392385333776474, Dice: 0.09608997404575348
EPOCH: 131, Loss: -2.5507204671700796
EPOCH: 131, Dice: 0.17018626828988392
Epoch: 132/199
Epoch: 132, Step: 20, Loss: -2.5931698262691496, Dice: 0.22033970057964325
Epoch: 132, Step: 40, Loss: -2.2401651561260225, Dice: 0.14797377586364746
EPOCH: 132, Loss: -2.5180599133173627
EPOCH: 132, Dice: 0.1652391456067562
Epoch: 133/199
Epoch: 133, Step: 20, Loss: -2.2435100257396696, Dice: 0.17300786077976227
Epoch: 133, Step: 40, Loss: -2.60181924700737, Dice: 0.19433686137199402
EPOCH: 133, Loss: -2.5651629587014515
EPOCH: 133, Dice: 0.16624541456500688
Epoch: 134/199
Epoch: 134, Step: 20, Loss: -2.4315671056509016, Dice: 0.21344749629497528
Epoch: 134, Step: 40, Loss: -2.3004067182540893, Dice: 0.13987641036510468
